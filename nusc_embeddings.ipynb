{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9101f608",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Descriptive Metadata, part 3\n",
    "\n",
    "## Word Embeddings with Word2Vec\n",
    "\n",
    "### Newcastle University Special Collections and University of Edinburgh Archives\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "* [Train Embeddings](#train-embeddings)\n",
    "* [Analysis](#analysis)\n",
    "  * [Gendered Terms and Adjectives](#gendered-terms-and-adjectives)\n",
    "  * [Names and Adjectives](#names-and-adjectives)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0954c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emb_utils\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, re, glob, string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2546326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the models\n",
    "emb_model_dir = \"embedding_models/\"\n",
    "Path(emb_model_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efde6b5",
   "metadata": {},
   "source": [
    "Other files (from `analysis_metadata_nusc.ipynb`) to experiment with creating embeddings with include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_dir = \"data/\"\n",
    "nusc_lower = \"nusc_descriptions_lower.txt\"  # includes numbers and punctuation attached to (not separating, like periods or commas) a token (i.e., the backslashes in 5/1/1)\n",
    "nusc_lower_alpha = \"nusc_descriptions_lower_alpha.txt\"\n",
    "nusc_lower_alpha_no_stopwords = \"nusc_descriptions_lower_alpha_no_stopwords.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383d5d5",
   "metadata": {},
   "source": [
    "## Train Embeddings\n",
    "\n",
    "Use [Word2Vec](https://perma.cc/R282-M8UM)* to create custom word embeddings from the Newcastle and Edinburgh datasets.\n",
    "\n",
    "**Check out [this resource](https://perma.cc/49GV-E236) for an illustrated explanation of Word2Vec.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65480c",
   "metadata": {},
   "source": [
    "First we'll evaluate how different parameter combinations represent the corpus to determine whether to use skip-gram or continuous bag-of-words, and what to set `context_window` and `min_count`, to. We'll stick with 100 for the dimensions of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b83f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_files = [nusc_lower, nusc_lower_alpha, nusc_lower_alpha_no_stopwords]\n",
    "file_paths = [nusc_dir+f for f in nusc_files]\n",
    "params = {\n",
    "    \"file_paths\": file_paths, \n",
    "    \"arch\": [0, 1], \n",
    "    \"min_count\": [3, 4, 5], \n",
    "    \"window\": [6, 8, 10],     # Generally ~10 is suitable for skip-gram and ~5 is suitable for CBOW\n",
    "    \"vector_size\": [100]      # Default is 100\n",
    "    }\n",
    "similar_words1 = [\"photograph\", \"photographs\"]\n",
    "similar_words2 = [\"influential\", \"greatest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd2d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "            # corpus_path = file_path\n",
    "            for line in open(corpus_path):\n",
    "                yield utils.simple_preprocess(line)  # assumes one doc per line, tokens separated by whitespace in each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecdb1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/dtt4chrx6lgcgnfz6r_z5ymm0000gn/T/ipykernel_8145/4275891600.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row])\n"
     ]
    }
   ],
   "source": [
    "architectures = params[\"arch\"]\n",
    "windows = params[\"window\"]\n",
    "min_counts = params[\"min_count\"]\n",
    "vector_sizes = params[\"vector_size\"]\n",
    "sim_col1 = f\"cosine_similarity_{similar_words1[0]}_{similar_words1[1]}\"\n",
    "sim_col2 = f\"cosine_similarity_{similar_words2[0]}_{similar_words2[1]}\"\n",
    "df = pd.DataFrame(columns=[\n",
    "    \"file\", \"architecture\", \"context_window\", \"min_freq_count\", \"vector_size\", sim_col1, sim_col2\n",
    "    ])\n",
    "for file_path in file_paths:\n",
    "    corpus_path = file_path\n",
    "    sentences = MyCorpus()\n",
    "    for a in architectures:\n",
    "        for min_count in min_counts:\n",
    "            for w in windows:\n",
    "                for vector_size in vector_sizes:\n",
    "                    # print(file_path, a, min_count, w, vector_size)\n",
    "                    model = Word2Vec(\n",
    "                        sentences=sentences, \n",
    "                        window=w,\n",
    "                        min_count=min_count, \n",
    "                        workers=3,        # Default is 3\n",
    "                        epochs=5, \n",
    "                        sg=a,\n",
    "                        vector_size=vector_size\n",
    "                    )\n",
    "                    sim1 = model.wv.similarity(similar_words1[0], similar_words1[1])\n",
    "                    sim2 = model.wv.similarity(similar_words2[0], similar_words2[1])\n",
    "                    new_row = pd.DataFrame.from_dict({\n",
    "                        \"file\":[file_path], \"architecture\":[a], \"context_window\":[w], \n",
    "                        \"min_freq_count\":[min_count], \"vector_size\":[vector_size], \n",
    "                        sim_col1 : [sim1], sim_col2: [sim2]\n",
    "                        })\n",
    "                    df = pd.concat([df, new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146b2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>architecture</th>\n",
       "      <th>context_window</th>\n",
       "      <th>min_freq_count</th>\n",
       "      <th>vector_size</th>\n",
       "      <th>cosine_similarity_photograph_photographs</th>\n",
       "      <th>cosine_similarity_influential_greatest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/nusc_descriptions_lower.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.651196</td>\n",
       "      <td>0.861426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/nusc_descriptions_lower.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.840397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file architecture context_window  \\\n",
       "0  data/nusc_descriptions_lower.txt            0              6   \n",
       "0  data/nusc_descriptions_lower.txt            0              8   \n",
       "\n",
       "  min_freq_count vector_size  cosine_similarity_photograph_photographs  \\\n",
       "0              3         100                                  0.651196   \n",
       "0              3         100                                  0.652970   \n",
       "\n",
       "   cosine_similarity_influential_greatest  \n",
       "0                                0.861426  \n",
       "0                                0.840397  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d889040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(emb_model_dir+\"nusc_word2vec_model_eval1.csv\")  #nusc_word2vec_model_eval2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401bf27b",
   "metadata": {},
   "source": [
    "Based on the evaluation results, we'll use the lowercased alphabetic corpus that excludes stop words (`nusc_descriptions_lower_alpha_no_stopwords.txt`) and continuous bag of words (CBOW) for the architecture, as those resulted in the highest cosine similarity scores for the chosen word pairs in both evaluation runs.  A context window of 8 paired with a minimum token frequency count of 3 as well as a window of 6 paired with a min. count of 5 both yield results that are among the highest (top seven) cosine similarity scores.\n",
    "\n",
    "(These parameters returned a cosine similarity of about 0.70-0.71 for \"photograph\" and \"photographs,\" and 0.93-0.97 for \"influential\" and \"greatest.\")\n",
    "\n",
    "Since Gensim's Word2Vec documentation recommends a context window of about 5 for CBOW, let's use the latter set of parameters for our word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58916dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/nusc_descriptions_lower_alpha_no_stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "corpus_path = file_paths[2]\n",
    "print(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77658719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "window = 6           \n",
    "sg = 0\n",
    "if sg == 1:\n",
    "    arch = \"sg\"\n",
    "else:\n",
    "    arch = \"cbow\"\n",
    "min_count = 5\n",
    "vector_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_model = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    window=window,\n",
    "    min_count=min_count, \n",
    "    workers=3,             # Default is 3\n",
    "    epochs=5, \n",
    "    sg=sg,\n",
    "    vector_size=vector_size\n",
    "    )\n",
    "nusc_model.save(emb_model_dir+f\"nusc_word2vec_{arch}_{vector_size}d_context{window}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/9182 is of\n",
      "word #1/9182 is the\n",
      "word #2/9182 is and\n",
      "word #3/9182 is to\n",
      "word #4/9182 is in\n"
     ]
    }
   ],
   "source": [
    "# Look at a sample of the words in the model to make sure it was trained as expected\n",
    "for index, word in enumerate(nusc_model.wv.index_to_key):\n",
    "    if index == 5:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(nusc_model.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959becc",
   "metadata": {},
   "source": [
    "Let's investigate relationships between grammatically and lexically gendered words and the top most common adjectives from the `nusc_uoe_comarison` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91bf709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9337855577468872), ('dog', 0.8908532857894897), ('illustration', 0.872054934501648), ('bird', 0.8476430773735046), ('boy', 0.8368086814880371), ('caption', 0.8355693817138672), ('horse', 0.8285383582115173), ('men', 0.8200470805168152), ('fishing', 0.8187179565429688), ('fish', 0.8137270212173462)] [('boy', 0.8402321934700012), ('man', 0.8200470805168152), ('woman', 0.813395082950592), ('horse', 0.7978457808494568), ('illustration', 0.7831832766532898), ('fishing', 0.781781792640686), ('night', 0.765031635761261), ('birds', 0.7648122906684875), ('talking', 0.7642461657524109), ('dog', 0.7623046040534973)]\n",
      "\n",
      "[('horse', 0.9071115851402283), ('woman', 0.9002888798713684), ('holding', 0.8924639225006104), ('sat', 0.8841385245323181), ('talking', 0.8721470236778259), ('older', 0.8648854494094849), ('caption', 0.86201411485672), ('hat', 0.8616151809692383), ('grandma', 0.8555570840835571), ('wearing', 0.8542486429214478)] [('holly', 0.9339240193367004), ('tramp', 0.9275671243667603), ('isle', 0.9216631054878235), ('romans', 0.9212527275085449), ('dreams', 0.9199769496917725), ('lover', 0.9172711372375488), ('searching', 0.9157799482345581), ('jarpin', 0.9147245287895203), ('oz', 0.9147137403488159), ('biting', 0.9137909412384033)]\n"
     ]
    }
   ],
   "source": [
    "man_similar = nusc_model.wv.most_similar(\"man\", topn=10)\n",
    "men_similar = nusc_model.wv.most_similar(\"men\", topn=10)\n",
    "boy_similar = nusc_model.wv.most_similar(\"boy\", topn=10)\n",
    "boys_similar = nusc_model.wv.most_similar(\"boys\", topn=10)\n",
    "print(man_similar, men_similar)\n",
    "print()\n",
    "print(boy_similar, boys_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f60250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 0.9337854981422424), ('boy', 0.9002889394760132), ('hat', 0.8966806530952454), ('horse', 0.8709551095962524), ('dog', 0.8581132292747498), ('talking', 0.8508883118629456), ('holding', 0.8499537110328674), ('bird', 0.8389260768890381), ('illustration', 0.8326569199562073), ('sat', 0.8278467655181885)] [('ireland', 0.829063892364502), ('teaching', 0.7741239070892334), ('irish', 0.770521879196167), ('suffrage', 0.7630794644355774), ('traveller', 0.7527427673339844), ('politics', 0.7476858496665955), ('education', 0.7421779632568359), ('african', 0.727326512336731), ('peace', 0.7267255187034607), ('affairs', 0.7241491079330444)]\n",
      "\n",
      "[('playing', 0.8857541680335999), ('rod', 0.8604581952095032), ('outdoors', 0.8544914722442627), ('guides', 0.8522405624389648), ('clothes', 0.8401862978935242), ('swimming', 0.830213189125061), ('dress', 0.8267804384231567), ('northallerton', 0.8266317844390869), ('dancing', 0.8251681327819824), ('spending', 0.8245590925216675)] [('holding', 0.8831355571746826), ('dancing', 0.8781248331069946), ('band', 0.8685126900672913), ('climbing', 0.8584061861038208), ('flute', 0.8577030301094055), ('stood', 0.857370138168335), ('outside', 0.8538711667060852), ('seated', 0.8501628637313843), ('snow', 0.8499663472175598), ('caught', 0.8475770950317383)]\n"
     ]
    }
   ],
   "source": [
    "woman_similar = nusc_model.wv.most_similar(\"woman\", topn=10)\n",
    "women_similar = nusc_model.wv.most_similar(\"women\", topn=10)\n",
    "girl_similar = nusc_model.wv.most_similar(\"girl\", topn=10)\n",
    "girls_similar = nusc_model.wv.most_similar(\"girls\", topn=10)\n",
    "print(woman_similar, women_similar)\n",
    "print()\n",
    "print(girl_similar, girls_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce6c8e",
   "metadata": {},
   "source": [
    "Smaller context window seems better (6 or 8 rather than 10...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1ad19",
   "metadata": {},
   "source": [
    "### CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a514b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model parameters and associated embedding model file name's variables\n",
    "sentences = MyCorpus()\n",
    "window = 6           # generally ~10 is suitable for skip-gram and ~5 is suitable for CBOW\n",
    "sg = 0\n",
    "if sg == 1:\n",
    "    arch = \"sg\"\n",
    "else:\n",
    "    arch = \"cbow\"\n",
    "min_count = 2\n",
    "vector_size = 100    # Default is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b58c16e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_model = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    window=window,\n",
    "    min_count=min_count, \n",
    "    workers=3,        # Default is 3\n",
    "    epochs=5, \n",
    "    sg=sg,\n",
    "    vector_size=vector_size\n",
    "    )\n",
    "# nusc_model.save(emb_model_dir+f\"nusc_word2vec_{arch}_{vector_size}d_context{window}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "850a731a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/17326 is of\n",
      "word #1/17326 is the\n",
      "word #2/17326 is and\n",
      "word #3/17326 is to\n",
      "word #4/17326 is in\n",
      "word #5/17326 is from\n",
      "word #6/17326 is for\n",
      "word #7/17326 is letter\n",
      "word #8/17326 is on\n",
      "word #9/17326 is file\n"
     ]
    }
   ],
   "source": [
    "# Look at a sample of the words in the model to make sure it was trained as expected\n",
    "for index, word in enumerate(nusc_model.wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(nusc_model.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd53ea",
   "metadata": {},
   "source": [
    "Let's investigate the similarity of words we'd expect to be similar in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5db791b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('files', 0.7767755389213562),\n",
       " ('project', 0.7417789697647095),\n",
       " ('photogrpahs', 0.7277644276618958),\n",
       " ('brochure', 0.7108482718467712),\n",
       " ('masterplan', 0.6939000487327576),\n",
       " ('designs', 0.6929506659507751),\n",
       " ('concept', 0.6849844455718994),\n",
       " ('presentation', 0.6834692358970642),\n",
       " ('historical', 0.6816883087158203),\n",
       " ('maps', 0.6786699891090393)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"file\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords:\n",
    " ## SG\n",
    "# [('files', 0.7466872930526733),\n",
    "#  ('outgoing', 0.7317661643028259),\n",
    "#  ('incoming', 0.7259922027587891),\n",
    "#  ('crossrail', 0.7138091325759888),\n",
    "#  ('icl', 0.7008764743804932),\n",
    "#  ('edco', 0.6982001066207886),\n",
    "#  ('pr', 0.6961277723312378),\n",
    "#  ('scans', 0.6931055188179016),\n",
    "#  ('collaborator', 0.6898413896560669),\n",
    "#  ('bishopsgate', 0.68710857629776)]\n",
    "\n",
    " ## CBOW\n",
    "# [('files', 0.8331142663955688),\n",
    "#  ('historic', 0.7841407060623169),\n",
    "#  ('outgoing', 0.7751049995422363),\n",
    "#  ('edco', 0.7709203362464905),\n",
    "#  ('maps', 0.7653296589851379),\n",
    "#  ('brochures', 0.7587681412696838),\n",
    "#  ('divided', 0.7556792497634888),\n",
    "#  ('designs', 0.7539230585098267),\n",
    "#  ('preparation', 0.7517764568328857),\n",
    "#  ('presentation', 0.7514598369598389)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cfe27275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('postcard', 0.7146406173706055),\n",
       " ('brannon', 0.7076549530029297),\n",
       " ('diary', 0.6909405589103699),\n",
       " ('postcards', 0.6608390808105469),\n",
       " ('trip', 0.6601690649986267),\n",
       " ('death', 0.6571880578994751),\n",
       " ('crimea', 0.6488868594169617),\n",
       " ('trevelyan', 0.6360825300216675),\n",
       " ('bell', 0.6304318308830261),\n",
       " ('trusteeship', 0.6229152679443359)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"letters\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('testimonial', 0.6532636284828186),\n",
    "#  ('swanage', 0.6265147924423218),\n",
    "#  ('telegrams', 0.6239833235740662),\n",
    "#  ('capel', 0.6227788329124451),\n",
    "#  ('robin', 0.6210677623748779),\n",
    "#  ('rct', 0.6200641989707947),\n",
    "#  ('nettlecombe', 0.6174697875976562),\n",
    "#  ('cheyne', 0.6166645288467407),\n",
    "#  ('receipts', 0.6135836839675903),\n",
    "#  ('maconochie', 0.6127098798751831)]\n",
    "\n",
    " ## CBOW\n",
    "#  [('diary', 0.8785619735717773),\n",
    "#  ('rowcliffe', 0.8287729024887085),\n",
    "#  ('brewis', 0.8260412216186523),\n",
    "#  ('macaulay', 0.8240538835525513),\n",
    "#  ('death', 0.8071291446685791),\n",
    "#  ('diverse', 0.8017675280570984),\n",
    "#  ('trevelyan', 0.7953676581382751),\n",
    "#  ('bell', 0.7860344648361206),\n",
    "#  ('career', 0.7856048345565796),\n",
    "#  ('postcard', 0.7852859497070312)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a2fc176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('portraying', 0.7605535984039307),\n",
       " ('photo', 0.7457089424133301),\n",
       " ('canvas', 0.6874290108680725),\n",
       " ('white', 0.6861698627471924),\n",
       " ('portrait', 0.6805410385131836),\n",
       " ('photographs', 0.6617839336395264),\n",
       " ('fluid', 0.6378166675567627),\n",
       " ('woman', 0.6364460587501526),\n",
       " ('photographic', 0.6357232332229614),\n",
       " ('black', 0.6309189200401306)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"photograph\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('photographs', 0.6903167963027954),\n",
    "#  ('portrait', 0.6546804904937744),\n",
    "#  ('photo', 0.635033130645752),\n",
    "#  ('potentially', 0.5975172519683838),\n",
    "#  ('backed', 0.5960174798965454),\n",
    "#  ('relative', 0.5952077507972717),\n",
    "#  ('portraying', 0.5813989639282227),\n",
    "#  ('white', 0.5800067782402039),\n",
    "#  ('colour', 0.575546383857727),\n",
    "#  ('outside', 0.5735738277435303)]\n",
    "\n",
    " ## CBOW\n",
    "# [('photographs', 0.6903167963027954),\n",
    "#  ('portrait', 0.6546804904937744),\n",
    "#  ('photo', 0.635033130645752),\n",
    "#  ('potentially', 0.5975172519683838),\n",
    "#  ('backed', 0.5960174798965454),\n",
    "#  ('relative', 0.5952077507972717),\n",
    "#  ('portraying', 0.5813989639282227),\n",
    "#  ('white', 0.5800067782402039),\n",
    "#  ('colour', 0.575546383857727),\n",
    "#  ('outside', 0.5735738277435303)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "43f84da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.9410372972488403),\n",
       " ('dog', 0.9109161496162415),\n",
       " ('illustration', 0.8857969641685486),\n",
       " ('bird', 0.8558411002159119),\n",
       " ('boy', 0.8472152352333069),\n",
       " ('men', 0.8378831148147583),\n",
       " ('birds', 0.8346065282821655),\n",
       " ('fishing', 0.8319897651672363),\n",
       " ('foreground', 0.8214560747146606),\n",
       " ('watercolour', 0.8190545439720154)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"man\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('woman', 0.8484075665473938),\n",
    "#  ('boy', 0.8225122094154358),\n",
    "#  ('dressed', 0.8222455382347107),\n",
    "#  ('magistrate', 0.8101038336753845),\n",
    "#  ('smartly', 0.8084942102432251),\n",
    "#  ('talking', 0.8078976273536682),\n",
    "#  ('dog', 0.8016583323478699),\n",
    "#  ('fish', 0.7976317405700684),\n",
    "#  ('observing', 0.7971518039703369),\n",
    "#  ('grass', 0.7877422571182251)]\n",
    "\n",
    " ## CBOW\n",
    "#  [('woman', 0.8484075665473938),\n",
    "#  ('boy', 0.8225122094154358),\n",
    "#  ('dressed', 0.8222455382347107),\n",
    "#  ('magistrate', 0.8101038336753845),\n",
    "#  ('smartly', 0.8084942102432251),\n",
    "#  ('talking', 0.8078976273536682),\n",
    "#  ('dog', 0.8016583323478699),\n",
    "#  ('fish', 0.7976317405700684),\n",
    "#  ('observing', 0.7971518039703369),\n",
    "#  ('grass', 0.7877422571182251)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c440afea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.8657723069190979),\n",
       " ('man', 0.8378832340240479),\n",
       " ('woman', 0.8297742009162903),\n",
       " ('dog', 0.8235422372817993),\n",
       " ('talking', 0.8170042037963867),\n",
       " ('bird', 0.8152064085006714),\n",
       " ('birds', 0.8132823705673218),\n",
       " ('caption', 0.8104074001312256),\n",
       " ('hunting', 0.8051303029060364),\n",
       " ('uniform', 0.8033609986305237)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"men\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('talking', 0.7804786562919617),\n",
    "#  ('eating', 0.7744420170783997),\n",
    "#  ('killed', 0.7701953649520874),\n",
    "#  ('soldiers', 0.7627596259117126),\n",
    "#  ('waiter', 0.759706437587738),\n",
    "#  ('smartly', 0.7592019438743591),\n",
    "#  ('stags', 0.7579233646392822),\n",
    "#  ('deer', 0.7574462294578552),\n",
    "#  ('caption', 0.7534621357917786),\n",
    "#  ('rabbits', 0.7507340312004089)]\n",
    "\n",
    " ## CBOW\n",
    "# [('talking', 0.7804786562919617),\n",
    "#  ('eating', 0.7744420170783997),\n",
    "#  ('killed', 0.7701953649520874),\n",
    "#  ('soldiers', 0.7627596259117126),\n",
    "#  ('waiter', 0.759706437587738),\n",
    "#  ('smartly', 0.7592019438743591),\n",
    "#  ('stags', 0.7579233646392822),\n",
    "#  ('deer', 0.7574462294578552),\n",
    "#  ('caption', 0.7534621357917786),\n",
    "#  ('rabbits', 0.7507340312004089)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a68313fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.9410372376441956),\n",
       " ('boy', 0.9070931673049927),\n",
       " ('dog', 0.8777681589126587),\n",
       " ('bird', 0.8735437393188477),\n",
       " ('talking', 0.8582047820091248),\n",
       " ('foreground', 0.856869637966156),\n",
       " ('illustration', 0.8519386649131775),\n",
       " ('birds', 0.8442080616950989),\n",
       " ('hat', 0.8439050316810608),\n",
       " ('men', 0.8297741413116455)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"woman\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('wearing', 0.8845924139022827),\n",
    "#  ('holding', 0.8606200814247131),\n",
    "#  ('boy', 0.8556447625160217),\n",
    "#  ('knitting', 0.8531962633132935),\n",
    "#  ('man', 0.8484075665473938),\n",
    "#  ('sat', 0.8451454043388367),\n",
    "#  ('backed', 0.8439164757728577),\n",
    "#  ('dressed', 0.8423831462860107),\n",
    "#  ('hat', 0.83938068151474),\n",
    "#  ('observing', 0.8337906002998352)]\n",
    "\n",
    " ## CBOW\n",
    "#  [('wearing', 0.8845924139022827),\n",
    "#  ('holding', 0.8606200814247131),\n",
    "#  ('boy', 0.8556447625160217),\n",
    "#  ('knitting', 0.8531962633132935),\n",
    "#  ('man', 0.8484075665473938),\n",
    "#  ('sat', 0.8451454043388367),\n",
    "#  ('backed', 0.8439164757728577),\n",
    "#  ('dressed', 0.8423831462860107),\n",
    "#  ('hat', 0.83938068151474),\n",
    "#  ('observing', 0.8337906002998352)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1bfa10a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ireland', 0.8727635145187378),\n",
       " ('politics', 0.7913272976875305),\n",
       " ('irish', 0.7819133400917053),\n",
       " ('education', 0.7754734754562378),\n",
       " ('russia', 0.7749536037445068),\n",
       " ('indian', 0.7719627022743225),\n",
       " ('peace', 0.7717481255531311),\n",
       " ('social', 0.7717099785804749),\n",
       " ('traveller', 0.7682931423187256),\n",
       " ('suffrage', 0.7645044922828674)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"women\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    "# [('suffrage', 0.7628691792488098),\n",
    "#  ('popular', 0.7125651240348816),\n",
    "#  ('traveller', 0.7020295262336731),\n",
    "#  ('federation', 0.6859576106071472),\n",
    "#  ('institutes', 0.6706743836402893),\n",
    "#  ('mountains', 0.667505145072937),\n",
    "#  ('unemployment', 0.6652866005897522),\n",
    "#  ('careers', 0.6585383415222168),\n",
    "#  ('adults', 0.6571559906005859),\n",
    "#  ('sixty', 0.6563506126403809)]\n",
    "\n",
    " ## CBOW\n",
    "# [('suffrage', 0.7628691792488098),\n",
    "#  ('popular', 0.7125651240348816),\n",
    "#  ('traveller', 0.7020295262336731),\n",
    "#  ('federation', 0.6859576106071472),\n",
    "#  ('institutes', 0.6706743836402893),\n",
    "#  ('mountains', 0.667505145072937),\n",
    "#  ('unemployment', 0.6652866005897522),\n",
    "#  ('careers', 0.6585383415222168),\n",
    "#  ('adults', 0.6571559906005859),\n",
    "#  ('sixty', 0.6563506126403809)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d036195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('retail', 0.9050933122634888),\n",
       " ('space', 0.9026519656181335),\n",
       " ('spaces', 0.9018585085868835),\n",
       " ('facilities', 0.886414110660553),\n",
       " ('areas', 0.8766377568244934),\n",
       " ('water', 0.8765712380409241),\n",
       " ('residential', 0.8642987608909607),\n",
       " ('structure', 0.8596487641334534),\n",
       " ('reuse', 0.851976752281189),\n",
       " ('massing', 0.8495070934295654)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"key\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('strategies', 0.8460091948509216),\n",
    "#  ('facilities', 0.8363745212554932),\n",
    "#  ('population', 0.83343505859375),\n",
    "#  ('constraints', 0.8240486979484558),\n",
    "#  ('hub', 0.8183097839355469),\n",
    "#  ('function', 0.8164852261543274),\n",
    "#  ('incorporating', 0.8153958320617676),\n",
    "#  ('achieve', 0.8151978850364685),\n",
    "#  ('designated', 0.8110092878341675),\n",
    "#  ('encompassing', 0.8107568025588989)]\n",
    "\n",
    "  ## CBOW\n",
    "# [('strategies', 0.8460091948509216),\n",
    "#  ('facilities', 0.8363745212554932),\n",
    "#  ('population', 0.83343505859375),\n",
    "#  ('constraints', 0.8240486979484558),\n",
    "#  ('hub', 0.8183097839355469),\n",
    "#  ('function', 0.8164852261543274),\n",
    "#  ('incorporating', 0.8153958320617676),\n",
    "#  ('achieve', 0.8151978850364685),\n",
    "#  ('designated', 0.8110092878341675),\n",
    "#  ('encompassing', 0.8107568025588989)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9511d6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('important', 0.8529764413833618),\n",
       " ('crime', 0.8338021636009216),\n",
       " ('effectively', 0.8248555660247803),\n",
       " ('frequently', 0.8217456340789795),\n",
       " ('renowned', 0.8181887865066528),\n",
       " ('body', 0.8177512884140015),\n",
       " ('language', 0.8141488432884216),\n",
       " ('languages', 0.8141064643859863),\n",
       " ('among', 0.8137490749359131),\n",
       " ('countries', 0.8130801916122437)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"influential\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('renowned', 0.9030014276504517),\n",
    "#  ('controversial', 0.896609365940094),\n",
    "#  ('era', 0.8870092630386353),\n",
    "#  ('haibun', 0.876724898815155),\n",
    "#  ('négritude', 0.8765851855278015),\n",
    "#  ('dagger', 0.8763759732246399),\n",
    "#  ('aged', 0.875598669052124),\n",
    "#  ('finest', 0.8741796016693115),\n",
    "#  ('thirty', 0.872181236743927),\n",
    "#  ('reviewer', 0.870881974697113)]\n",
    "\n",
    " ## CBOW\n",
    "# [('renowned', 0.9030014276504517),\n",
    "#  ('controversial', 0.896609365940094),\n",
    "#  ('era', 0.8870092630386353),\n",
    "#  ('haibun', 0.876724898815155),\n",
    "#  ('négritude', 0.8765851855278015),\n",
    "#  ('dagger', 0.8763759732246399),\n",
    "#  ('aged', 0.875598669052124),\n",
    "#  ('finest', 0.8741796016693115),\n",
    "#  ('thirty', 0.872181236743927),\n",
    "#  ('reviewer', 0.870881974697113)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95e42de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relevance', 0.8954179883003235),\n",
       " ('remit', 0.8918818235397339),\n",
       " ('extensively', 0.8898897767066956),\n",
       " ('exploring', 0.8885937929153442),\n",
       " ('ahead', 0.8843324780464172),\n",
       " ('similar', 0.8808154463768005),\n",
       " ('output', 0.8806847929954529),\n",
       " ('employed', 0.8798457980155945),\n",
       " ('deliberately', 0.8797436356544495),\n",
       " ('maintain', 0.8794825077056885)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nusc_model.wv.most_similar(\"significant\", topn=10)\n",
    "\n",
    "### with nusc_lower_alpha_no_stopwords\n",
    " ## SG\n",
    "# [('covered', 0.8478525876998901),\n",
    "#  ('resources', 0.8471731543540955),\n",
    "#  ('online', 0.8461249470710754),\n",
    "#  ('demonstrate', 0.8445181250572205),\n",
    "#  ('bids', 0.8415424823760986),\n",
    "#  ('themes', 0.8382758498191833),\n",
    "#  ('initiatives', 0.8319141268730164),\n",
    "#  ('sector', 0.8317221403121948),\n",
    "#  ('basis', 0.8311277031898499),\n",
    "#  ('objectives', 0.8302891850471497)]\n",
    "\n",
    " ## CBOW\n",
    "# [('covered', 0.8478525876998901),\n",
    "#  ('resources', 0.8471731543540955),\n",
    "#  ('online', 0.8461249470710754),\n",
    "#  ('demonstrate', 0.8445181250572205),\n",
    "#  ('bids', 0.8415424823760986),\n",
    "#  ('themes', 0.8382758498191833),\n",
    "#  ('initiatives', 0.8319141268730164),\n",
    "#  ('sector', 0.8317221403121948),\n",
    "#  ('basis', 0.8311277031898499),\n",
    "#  ('objectives', 0.8302891850471497)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc1e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e992394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e67e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "359746c3",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "How similar are pretrained vectors to th custom vectors?\n",
    "\n",
    "## Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261950b",
   "metadata": {},
   "source": [
    "#### Floret \n",
    "\n",
    "(fastText + Bloom embeddings (spaCy's default) - see documentation [here](https://github.com/explosion/floret))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
