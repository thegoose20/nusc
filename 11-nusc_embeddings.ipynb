{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9101f608",
   "metadata": {},
   "source": [
    "# Word Embeddings with Word2Vec\n",
    "\n",
    "## Newcastle University Special Collections\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "* [Training](#train-embeddings)\n",
    "* [Analysis](#analysis)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0954c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emb_utils\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, re, glob, string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2546326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the models\n",
    "emb_model_dir = \"embedding_models/\"\n",
    "Path(emb_model_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efde6b5",
   "metadata": {},
   "source": [
    "Other files (from `analysis_metadata_nusc.ipynb`) to experiment with creating embeddings with include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_dir = \"data/\"\n",
    "nusc_lower = \"nusc_descriptions_lower.txt\"  # includes numbers and punctuation attached to (not separating, like periods or commas) a token (i.e., the backslashes in 5/1/1)\n",
    "nusc_lower_alpha = \"nusc_descriptions_lower_alpha.txt\"\n",
    "nusc_lower_alpha_no_stopwords = \"nusc_descriptions_lower_alpha_no_stopwords.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383d5d5",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Use [Word2Vec](https://perma.cc/R282-M8UM)* to create custom word embeddings from the Newcastle and Edinburgh datasets.\n",
    "\n",
    "**Check out [this resource](https://perma.cc/49GV-E236) for an illustrated explanation of Word2Vec.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65480c",
   "metadata": {},
   "source": [
    "First we'll evaluate how different parameter combinations represent the corpus to determine whether to use skip-gram or continuous bag-of-words, and what to set `context_window` and `min_count`, to. We'll stick with 100 for the dimensions of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b83f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_files = [nusc_lower, nusc_lower_alpha, nusc_lower_alpha_no_stopwords]\n",
    "file_paths = [nusc_dir+f for f in nusc_files]\n",
    "params = {\n",
    "    \"file_paths\": file_paths, \n",
    "    \"arch\": [0, 1], \n",
    "    \"min_count\": [3, 4, 5], \n",
    "    \"window\": [6, 8, 10],     # Generally ~10 is suitable for skip-gram and ~5 is suitable for CBOW\n",
    "    \"vector_size\": [100]      # Default is 100\n",
    "    }\n",
    "similar_words1 = [\"photograph\", \"photographs\"]\n",
    "similar_words2 = [\"influential\", \"greatest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd2d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    def __iter__(self):\n",
    "            # corpus_path = file_path\n",
    "            for line in open(corpus_path):\n",
    "                yield utils.simple_preprocess(line)  # assumes one doc per line, tokens separated by whitespace in each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecdb1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/dtt4chrx6lgcgnfz6r_z5ymm0000gn/T/ipykernel_8145/4275891600.py:34: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row])\n"
     ]
    }
   ],
   "source": [
    "architectures = params[\"arch\"]\n",
    "windows = params[\"window\"]\n",
    "min_counts = params[\"min_count\"]\n",
    "vector_sizes = params[\"vector_size\"]\n",
    "sim_col1 = f\"cosine_similarity_{similar_words1[0]}_{similar_words1[1]}\"\n",
    "sim_col2 = f\"cosine_similarity_{similar_words2[0]}_{similar_words2[1]}\"\n",
    "df = pd.DataFrame(columns=[\n",
    "    \"file\", \"architecture\", \"context_window\", \"min_freq_count\", \"vector_size\", sim_col1, sim_col2\n",
    "    ])\n",
    "for file_path in file_paths:\n",
    "    corpus_path = file_path\n",
    "    sentences = MyCorpus()\n",
    "    for a in architectures:\n",
    "        for min_count in min_counts:\n",
    "            for w in windows:\n",
    "                for vector_size in vector_sizes:\n",
    "                    # print(file_path, a, min_count, w, vector_size)\n",
    "                    model = Word2Vec(\n",
    "                        sentences=sentences, \n",
    "                        window=w,\n",
    "                        min_count=min_count, \n",
    "                        workers=3,        # Default is 3\n",
    "                        epochs=5, \n",
    "                        sg=a,\n",
    "                        vector_size=vector_size\n",
    "                    )\n",
    "                    sim1 = model.wv.similarity(similar_words1[0], similar_words1[1])\n",
    "                    sim2 = model.wv.similarity(similar_words2[0], similar_words2[1])\n",
    "                    new_row = pd.DataFrame.from_dict({\n",
    "                        \"file\":[file_path], \"architecture\":[a], \"context_window\":[w], \n",
    "                        \"min_freq_count\":[min_count], \"vector_size\":[vector_size], \n",
    "                        sim_col1 : [sim1], sim_col2: [sim2]\n",
    "                        })\n",
    "                    df = pd.concat([df, new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146b2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>architecture</th>\n",
       "      <th>context_window</th>\n",
       "      <th>min_freq_count</th>\n",
       "      <th>vector_size</th>\n",
       "      <th>cosine_similarity_photograph_photographs</th>\n",
       "      <th>cosine_similarity_influential_greatest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/nusc_descriptions_lower.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.651196</td>\n",
       "      <td>0.861426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/nusc_descriptions_lower.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.652970</td>\n",
       "      <td>0.840397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file architecture context_window  \\\n",
       "0  data/nusc_descriptions_lower.txt            0              6   \n",
       "0  data/nusc_descriptions_lower.txt            0              8   \n",
       "\n",
       "  min_freq_count vector_size  cosine_similarity_photograph_photographs  \\\n",
       "0              3         100                                  0.651196   \n",
       "0              3         100                                  0.652970   \n",
       "\n",
       "   cosine_similarity_influential_greatest  \n",
       "0                                0.861426  \n",
       "0                                0.840397  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d889040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(emb_model_dir+\"nusc_word2vec_model_eval1.csv\")  #nusc_word2vec_model_eval2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401bf27b",
   "metadata": {},
   "source": [
    "Based on the evaluation results, we'll use the lowercased alphabetic corpus that excludes stop words (`nusc_descriptions_lower_alpha_no_stopwords.txt`) and continuous bag of words (CBOW) for the architecture, as those resulted in the highest cosine similarity scores for the chosen word pairs in both evaluation runs.  A context window of 8 paired with a minimum token frequency count of 3 as well as a window of 6 paired with a min. count of 5 both yield results that are among the highest (top seven) cosine similarity scores.\n",
    "\n",
    "(These parameters returned a cosine similarity of about 0.70-0.71 for \"photograph\" and \"photographs,\" and 0.93-0.97 for \"influential\" and \"greatest.\")\n",
    "\n",
    "Since Gensim's Word2Vec documentation recommends a context window of about 5 for CBOW, let's use the latter set of parameters for our word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58916dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/nusc_descriptions_lower_alpha_no_stopwords.txt\n"
     ]
    }
   ],
   "source": [
    "corpus_path = file_paths[2]\n",
    "print(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77658719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()\n",
    "window = 6           \n",
    "sg = 0\n",
    "if sg == 1:\n",
    "    arch = \"sg\"\n",
    "else:\n",
    "    arch = \"cbow\"\n",
    "min_count = 5\n",
    "vector_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c0b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusc_model = Word2Vec(\n",
    "    sentences=sentences, \n",
    "    window=window,\n",
    "    min_count=min_count, \n",
    "    workers=3,             # Default is 3\n",
    "    epochs=5, \n",
    "    sg=sg,\n",
    "    vector_size=vector_size\n",
    "    )\n",
    "nusc_model.save(emb_model_dir+f\"nusc_word2vec_{arch}_{vector_size}d_context{window}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fa9a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/8705 is letter\n",
      "word #1/8705 is file\n",
      "word #2/8705 is consists\n",
      "word #3/8705 is includes\n",
      "word #4/8705 is concerning\n"
     ]
    }
   ],
   "source": [
    "# Look at a sample of the words in the model to make sure it was trained as expected\n",
    "for index, word in enumerate(nusc_model.wv.index_to_key):\n",
    "    if index == 5:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(nusc_model.wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959becc",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's investigate relationships between grammatically and lexically gendered words and the top most common adjectives from the `nusc_uoe_comarison` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = [\"man\", \"men\", \"boy\", \"boys\"]\n",
    "fem = [\"woman\", \"women\", \"girl\", \"girls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4595942b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>category</th>\n",
       "      <th>top10_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(permissions, 0.7298351526260376)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(memos, 0.7233912944793701)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  category            top10_cosine_similarity\n",
       "0  woman  feminine  (permissions, 0.7298351526260376)\n",
       "0  woman  feminine        (memos, 0.7233912944793701)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = []\n",
    "for w in fem:\n",
    "    similar += [nusc_model.wv.most_similar(word, topn=10)]\n",
    "cat = [\"feminine\"]*len(fem)\n",
    "df_fem = pd.DataFrame.from_dict({\"word\":fem, \"category\":cat, \"top10_cosine_similarity\":similar})\n",
    "df_fem = df_fem.explode(\"top10_cosine_similarity\")\n",
    "df_fem.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91bf709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>category</th>\n",
       "      <th>top10_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(permissions, 0.7298351526260376)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(memos, 0.7233912944793701)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word   category            top10_cosine_similarity\n",
       "0  man  masculine  (permissions, 0.7298351526260376)\n",
       "0  man  masculine        (memos, 0.7233912944793701)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar = []\n",
    "for w in mas:\n",
    "    similar += [nusc_model.wv.most_similar(word, topn=10)]\n",
    "cat = [\"masculine\"]*len(mas)\n",
    "df_mas = pd.DataFrame.from_dict({\"word\":mas, \"category\":cat, \"top10_cosine_similarity\":similar})\n",
    "df_mas = df_mas.explode(\"top10_cosine_similarity\")\n",
    "df_mas.head(2)\n",
    "# f = \"embedding_models/gender_analysis.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f60250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>category</th>\n",
       "      <th>top10_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boys</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(publications, 0.6969491243362427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(publications, 0.6969491243362427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(publications, 0.6969491243362427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>girls</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(publications, 0.6969491243362427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boy</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(publications, 0.6969491243362427)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   category             top10_cosine_similarity\n",
       "3   boys  masculine  (publications, 0.6969491243362427)\n",
       "0  woman   feminine  (publications, 0.6969491243362427)\n",
       "2   girl   feminine  (publications, 0.6969491243362427)\n",
       "3  girls   feminine  (publications, 0.6969491243362427)\n",
       "2    boy  masculine  (publications, 0.6969491243362427)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gender = pd.concat([df_fem, df_mas])\n",
    "df_gender = df_gender.sort_values(by=\"top10_cosine_similarity\")\n",
    "df_gender.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b603609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>category</th>\n",
       "      <th>top10_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(bids, 0.6911782622337341)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(bids, 0.6911782622337341)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl</td>\n",
       "      <td>feminine</td>\n",
       "      <td>(bids, 0.6911782622337341)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>men</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(bids, 0.6911782622337341)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boy</td>\n",
       "      <td>masculine</td>\n",
       "      <td>(bids, 0.6911782622337341)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word   category     top10_cosine_similarity\n",
       "1  women   feminine  (bids, 0.6911782622337341)\n",
       "0    man  masculine  (bids, 0.6911782622337341)\n",
       "2   girl   feminine  (bids, 0.6911782622337341)\n",
       "1    men  masculine  (bids, 0.6911782622337341)\n",
       "2    boy  masculine  (bids, 0.6911782622337341)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d4c0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender.to_csv(\"embedding_models/gendered_word_cosine_similarity_top10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2eb6467f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['key', 'historic', 'influential', 'notable', 'significant', 'successful', 'major', 'distinctive']\n"
     ]
    }
   ],
   "source": [
    "# These adjectives were also analyzed using concordances\n",
    "old_adjs = [\"key\", \"historic\", \"influential\", \"notable\", \"significant\", \"successful\", \"major\", \"distinctive\", \"remarkable\"]\n",
    "adjs = []\n",
    "for a in old_adjs:\n",
    "    if a in nusc_model.wv.key_to_index:\n",
    "        adjs += [a]\n",
    "print(adjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a5c733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>word</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>key</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>key</td>\n",
       "      <td>women</td>\n",
       "      <td>-0.062030</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>key</td>\n",
       "      <td>girl</td>\n",
       "      <td>0.217084</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>key</td>\n",
       "      <td>girls</td>\n",
       "      <td>0.264650</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>historic</td>\n",
       "      <td>woman</td>\n",
       "      <td>0.020570</td>\n",
       "      <td>feminine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adjective   word  cosine_similarity  category\n",
       "0       key  woman           0.101171  feminine\n",
       "1       key  women          -0.062030  feminine\n",
       "2       key   girl           0.217084  feminine\n",
       "3       key  girls           0.264650  feminine\n",
       "4  historic  woman           0.020570  feminine"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_col, f_col, f_scores, = [], [], []\n",
    "for adj in adjs:\n",
    "    f_scores += [nusc_model.wv.similarity(f, adj) for f in fem]\n",
    "    adj_col += [adj for f in fem]\n",
    "    f_col += [f for f in fem]\n",
    "cat = [\"feminine\"]*len(f_col)\n",
    "df_adj_fem = pd.DataFrame.from_dict({\"adjective\": adj_col, \"word\": f_col, \"cosine_similarity\": f_scores, \"category\": cat})\n",
    "df_adj_fem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28c2b076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>word</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>key</td>\n",
       "      <td>man</td>\n",
       "      <td>0.055019</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>key</td>\n",
       "      <td>men</td>\n",
       "      <td>0.054343</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>key</td>\n",
       "      <td>boy</td>\n",
       "      <td>0.202730</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>key</td>\n",
       "      <td>boys</td>\n",
       "      <td>0.392058</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>historic</td>\n",
       "      <td>man</td>\n",
       "      <td>-0.124435</td>\n",
       "      <td>masculine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adjective  word  cosine_similarity   category\n",
       "0       key   man           0.055019  masculine\n",
       "1       key   men           0.054343  masculine\n",
       "2       key   boy           0.202730  masculine\n",
       "3       key  boys           0.392058  masculine\n",
       "4  historic   man          -0.124435  masculine"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_col, m_col, m_scores, = [], [], []\n",
    "for adj in adjs:\n",
    "    m_scores += [nusc_model.wv.similarity(m, adj) for m in mas]\n",
    "    adj_col += [adj for m in mas]\n",
    "    m_col += [m for m in mas]\n",
    "cat = [\"masculine\"]*len(f_col)\n",
    "df_adj_mas = pd.DataFrame.from_dict({\"adjective\": adj_col, \"word\": m_col, \"cosine_similarity\": m_scores, \"category\": cat})\n",
    "df_adj_mas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7eda98eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj = pd.concat([df_adj_fem, df_adj_mas])\n",
    "df_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3901be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj.to_csv(\"embedding_models/gendered_word_adj_cosine_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e6f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
