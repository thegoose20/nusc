{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d533ee6",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Descriptive Metadata\n",
    "\n",
    "### Newcastle University Special Collections and University of Edinburgh Archives\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "* [Description Lengths](#description-lengths)\n",
    "* [Gendered Language](#gendered-language)\n",
    "* [Parts of Speech](#parts-of-speech)\n",
    "  * [Adjectives](#adjectives)\n",
    "  * [Adverbs](#adverbs)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796ebf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c4cd7f",
   "metadata": {},
   "source": [
    "Create variables to reference the files and data points from the `analysis_metadata_XXX.ipynb` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_nusc = \"data/analysis/\"\n",
    "files_nusc = [\n",
    "    \"nusc_ead_descs_stats.csv\", \n",
    "    \"nusc_ead_gendered_lower_token_counts_ead.csv\", \"nusc_ead_gendered_capitalized_token_counts.csv\",\n",
    "    \"nusc_ead_descs_pos_tags.csv\",\n",
    "    \"nusc_ead_nltk_adj_token_counts.csv\", \"nusc_ead_nltk_adj_token_lower_counts.csv\",\n",
    "    \"nusc_ead_nltk_adv_token_counts.csv\", \"nusc_ead_nltk_adv_token_lower_counts.csv\",\n",
    "    \"nusc_ead_nltk_adj_token_counts.csv\", \"nusc_ead_nltk_adj_adv_stats.csv\"\n",
    "]\n",
    "nusc_descs_total = 75165\n",
    "nusc_sentences_total = 124592\n",
    "nusc_tokens_total = 1915370    # all tokens, with repeats\n",
    "nusc_vocab_size = 42531        # unique tokens, no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e6a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_uoe = \"data/uoe/analysis/\"\n",
    "files_uoe = [\n",
    "    \"uoe_ead_descs-oct2020_stats.csv\", \n",
    "    \"uoe_ead_gendered_lower_token_counts_oct2020.csv\", \"uoe_ead_gendered_capitalized_token_counts_oct2020.csv\",\n",
    "    \"uoe_ead_descs_oct2020_pos_tags.csv\", \n",
    "    \"uoe_descs_oct2020_nltk_adj_token_counts.csv\", \"uoe_descs_oct2020_nltk_adj_token_lower_counts.csv\",\n",
    "    \"uoe_descs_oct2020_nltk_adv_token_counts.csv\", \"uoe_descs_oct2020_nltk_adv_token_lower_counts.csv\",\n",
    "    \"uoe_descs_oct2020_nltk_adj_adv_counts.csv\", \"uoe_oct2020_nltk_adj_adv_stats.csv\"\n",
    "]\n",
    "uoe_descs_total = 27752\n",
    "uoe_sentences_total = 41671\n",
    "uoe_tokens_total = 542635     # all tokens, with repeats\n",
    "uoe_vocab_size = 40949        # unique tokens, no repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db363c",
   "metadata": {},
   "source": [
    "## Description Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48728f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)  # display floating point numbers with 3 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4709ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_per_description</th>\n",
       "      <th>tokens_per_description</th>\n",
       "      <th>tokens_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.658</td>\n",
       "      <td>25.482</td>\n",
       "      <td>17.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>1.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_deviation</th>\n",
       "      <td>2.396</td>\n",
       "      <td>63.481</td>\n",
       "      <td>16.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum</th>\n",
       "      <td>91.000</td>\n",
       "      <td>2296.000</td>\n",
       "      <td>1676.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>124592.000</td>\n",
       "      <td>1915370.000</td>\n",
       "      <td>1915370.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sentences_per_description  tokens_per_description  \\\n",
       "mean                                    1.658                  25.482   \n",
       "median                                  1.000                   9.000   \n",
       "standard_deviation                      2.396                  63.481   \n",
       "minimum                                 1.000                   0.000   \n",
       "maximum                                91.000                2296.000   \n",
       "total                              124592.000             1915370.000   \n",
       "\n",
       "                    tokens_per_sentence  \n",
       "mean                             17.538  \n",
       "median                           13.000  \n",
       "standard_deviation               16.256  \n",
       "minimum                           1.000  \n",
       "maximum                        1676.000  \n",
       "total                       1915370.000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len_nusc = pd.read_csv(dir_nusc + \"nusc_ead_descs_stats.csv\", index_col=0)\n",
    "df_len_nusc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a1b4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_per_description</th>\n",
       "      <th>tokens_per_description</th>\n",
       "      <th>tokens_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.502</td>\n",
       "      <td>19.553</td>\n",
       "      <td>1.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>standard_deviation</th>\n",
       "      <td>5.377</td>\n",
       "      <td>97.627</td>\n",
       "      <td>5.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum</th>\n",
       "      <td>742.000</td>\n",
       "      <td>14097.000</td>\n",
       "      <td>742.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>41671.000</td>\n",
       "      <td>542635.000</td>\n",
       "      <td>542635.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sentences_per_description  tokens_per_description  \\\n",
       "mean                                    1.502                  19.553   \n",
       "median                                  1.000                  10.000   \n",
       "standard_deviation                      5.377                  97.627   \n",
       "minimum                                 1.000                   1.000   \n",
       "maximum                               742.000               14097.000   \n",
       "total                               41671.000              542635.000   \n",
       "\n",
       "                    tokens_per_sentence  \n",
       "mean                              1.502  \n",
       "median                            1.000  \n",
       "standard_deviation                5.377  \n",
       "minimum                           1.000  \n",
       "maximum                         742.000  \n",
       "total                        542635.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_len_uoe = pd.read_csv(dir_uoe + \"uoe_ead_descs_oct2020_stats.csv\", index_col=0)\n",
    "df_len_uoe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e7c4",
   "metadata": {},
   "source": [
    "Edinburgh's data shows more tokens per description on average, which I hadn't expected, though the median is greater for Edinburgh (10 vs. 9).  There is also greater variation in description lengths in the Edinburgh data relative to the Newcastle data.  Also, the maximum number of tokens in a single description is far larger (14,097 vs. 2,296), as is the maximum number of sentences (742 vs. 91). \n",
    "\n",
    "TOKENS PER SENTENCE FOR UOE DOESN'T LOOK RIGHT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445bd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tokens_per_desc = list(df_len_uoe[\"tokens_per_description\"])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nusc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
