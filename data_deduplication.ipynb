{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Deduplication\n",
    "\n",
    "Remove duplicate descriptions from the exported data for manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data analysis\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Custom variables\n",
    "import config\n",
    "\n",
    "# For reading and writing data\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THS_unclassified.csv', 'OBR_unclassified.csv', '.DS_Store', 'BXB_unclassified.csv', 'GB_unclassified.csv', 'WCT_unclassified.csv', 'deduplicated', 'CPT_unclassified.csv', 'SW_unclassified.csv', 'CHE_unclassified.csv', 'SH_unclassified.csv', 'HL_unclassified.csv', 'BP_unclassified.csv']\n"
     ]
    }
   ],
   "source": [
    "unclf_dir = \"data/extracted/for_review/unclassified/\"\n",
    "file_names = os.listdir(unclf_dir)\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for the deduplicated, unclassified descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_dir = \"data/extracted/for_review/unclassified/deduplicated\"\n",
    "Path(dedup_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deduplicate the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implodeDataFrame(df, cols_to_groupby):\n",
    "    cols_to_agg = list(df.columns)\n",
    "    for col in cols_to_groupby:\n",
    "        cols_to_agg.remove(col)\n",
    "    agg_dict = dict.fromkeys(cols_to_agg, lambda x: x.tolist())\n",
    "    return df.groupby(cols_to_groupby).agg(agg_dict).reset_index().set_index(cols_to_groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading THS_unclassified.csv\n",
      "(10851, 5) (4865, 5)\n",
      "Reading OBR_unclassified.csv\n",
      "(532, 5) (455, 5)\n",
      "Reading BXB_unclassified.csv\n",
      "(10884, 5) (6137, 5)\n",
      "Reading GB_unclassified.csv\n",
      "(428, 5) (32, 5)\n",
      "Reading WCT_unclassified.csv\n",
      "(1122, 5) (1065, 5)\n",
      "Reading CPT_unclassified.csv\n",
      "(6885, 5) (4378, 5)\n",
      "Reading SW_unclassified.csv\n",
      "(2114, 5) (1642, 5)\n",
      "Reading CHE_unclassified.csv\n",
      "(268, 5) (266, 5)\n",
      "Reading SH_unclassified.csv\n",
      "(360, 5) (290, 5)\n",
      "Reading HL_unclassified.csv\n",
      "(219, 5) (211, 5)\n",
      "Reading BP_unclassified.csv\n",
      "(562, 5) (508, 5)\n",
      "Total rows: 19849\n"
     ]
    }
   ],
   "source": [
    "row_count = 0\n",
    "all_descs = []\n",
    "for f in file_names:\n",
    "    if \"_unclassified.csv\" in f:\n",
    "        print(\"Reading\", f)\n",
    "        # Read the file as a DataFrame\n",
    "        df = pd.read_csv(unclf_dir+f, index_col=0)\n",
    "\n",
    "        # Remove the empty column (where manual reviewers will make notes)\n",
    "        df = df.drop(columns=[\"gender_bias?\"])\n",
    "        imploded = implodeDataFrame(df, [\"doc\",\"eadid\"]).reset_index()\n",
    "        print(df.shape, imploded.shape)\n",
    "        row_count += imploded.shape[0]\n",
    "        all_descs += list(imploded[\"doc\"])\n",
    "        assert imploded.shape[0] < df.shape[0], \"There should be fewer rows in the DataFrame after imploding it.\"\n",
    "\n",
    "        # Add a new empty column for manual reviewers to record their notes\n",
    "        empty_col = [\"\"]*imploded.shape[0]\n",
    "        imploded.insert(len(imploded.columns), \"gender_bias?\", empty_col)\n",
    "        # imploded.head()\n",
    "\n",
    "        # Write the imploded DataFrame into the newly created directory\n",
    "        imploded.to_csv(dedup_dir+\"/\"+f)\n",
    "print(\"Total rows:\", row_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THS_unclassified.csv', 'OBR_unclassified.csv', 'BXB_unclassified.csv', 'GB_unclassified.csv', 'WCT_unclassified.csv', 'CPT_unclassified.csv', 'SW_unclassified.csv', 'CHE_unclassified.csv', 'SH_unclassified.csv', 'HL_unclassified.csv', 'BP_unclassified.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(dedup_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 2188536\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "for desc in all_descs:\n",
    "    word_count += len(desc)\n",
    "print(\"Total words:\", word_count)  # about 2 million"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nusc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
