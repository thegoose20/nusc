{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis: Manual Codes vs. Model Classifications\n",
    "\n",
    "Compare and contrast the manual coding of descriptions for *Omission* and *Stereotype* to the predictions of the Baseline Omission and Stereotype Classifier and the Omission and Stereotype Classifier with linguistic features.\n",
    "\n",
    "***\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "I. [Prepare Data for Manual Review, part 2](#i)\n",
    "\n",
    "II. [Analyze Agreement, part 1](#ii)\n",
    "\n",
    "   - [Manual vs. Baseline OSC](#ii-i)\n",
    "   - [Manual vs. LCOSC](#ii-ii)\n",
    "   - [Baseline OSC vs. LCOSC](#ii-iii)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom variables and functions\n",
    "import clf_utils\n",
    "import config\n",
    "\n",
    "# For data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For reading and writing files and directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from joblib import load\n",
    "\n",
    "# For evaluation of classification/coding\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read manually coded and classified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>index</th>\n",
       "      <th>doc</th>\n",
       "      <th>linguistic_prediction</th>\n",
       "      <th>gender_bias_manual</th>\n",
       "      <th>omission_manual</th>\n",
       "      <th>stereotype_manual</th>\n",
       "      <th>type</th>\n",
       "      <th>note</th>\n",
       "      <th>eadid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>field</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>lcosc_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11452</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>11452</td>\n",
       "      <td>Drafts and meeting notes relating to the creat...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/01/01</td>\n",
       "      <td>scopecontent</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11467</td>\n",
       "      <td>[16, 17, 15]</td>\n",
       "      <td>11467</td>\n",
       "      <td>CHE Supporters Review</td>\n",
       "      <td>['O']</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/02/04</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>()</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                           token_id  index  \\\n",
       "0           11452  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  11452   \n",
       "1           11467                                       [16, 17, 15]  11467   \n",
       "\n",
       "                                                 doc linguistic_prediction  \\\n",
       "0  Drafts and meeting notes relating to the creat...                 ['O']   \n",
       "1                              CHE Supporters Review                 ['O']   \n",
       "\n",
       "  gender_bias_manual omission_manual stereotype_manual type note eadid  \\\n",
       "0                  n               n                 n  NaN  NaN   CHE   \n",
       "1                  n               n                 n  NaN  NaN   CHE   \n",
       "\n",
       "       rowid         field baseline_prediction lcosc_prediction  \n",
       "0  CHE/01/01  scopecontent                  ()               ()  \n",
       "1  CHE/02/04     unittitle                  ()               ()  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = config.coded_and_classified\n",
    "f = \"manually_coded_baselineosc_lcosc.csv\"\n",
    "df = pd.read_csv(dir+f)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the model predictions' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                        12168\n",
       "[Omission]                  164\n",
       "[Stereotype]                  3\n",
       "[Omission, Stereotype]        2\n",
       "Name: baseline_prediction, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"baseline_prediction\"] = df[\"baseline_prediction\"].apply(lambda x: x.strip(\"()\"))\n",
    "df[\"baseline_prediction\"] = df[\"baseline_prediction\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "df[\"baseline_prediction\"] = df[\"baseline_prediction\"].apply(lambda x: x.strip(\",\"))\n",
    "df[\"baseline_prediction\"] = df[\"baseline_prediction\"].apply(lambda x: x.split(\", \"))\n",
    "df.baseline_prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                        12040\n",
       "[Omission]                  291\n",
       "[Omission, Stereotype]        3\n",
       "[Stereotype]                  3\n",
       "Name: lcosc_prediction, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lcosc_prediction\"] = df[\"lcosc_prediction\"].apply(lambda x: x.strip(\"()\"))\n",
    "df[\"lcosc_prediction\"] = df[\"lcosc_prediction\"].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "df[\"lcosc_prediction\"] = df[\"lcosc_prediction\"].apply(lambda x: x.strip(\",\"))\n",
    "df[\"lcosc_prediction\"] = df[\"lcosc_prediction\"].apply(lambda x: x.split(\", \"))\n",
    "df.lcosc_prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]                        12287\n",
       "[Omission]                   45\n",
       "[Stereotype]                  3\n",
       "[Omission, Stereotype]        2\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type\"] = df[\"type\"].replace(\"Sterotype\", \"Stereotype\")\n",
    "df[\"type\"] = df[\"type\"].replace(\"Stereotype and Omission\", \"Omission, Stereotype\")\n",
    "df[\"type\"] = df[\"type\"].fillna(\"\")\n",
    "df[\"type\"] = df[\"type\"].apply(lambda x: x.split(\", \"))\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"i\"></a>\n",
    "### I. Prepare Data for Manual Review, part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>second_manual_code</th>\n",
       "      <th>second_note</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>lcosc_prediction</th>\n",
       "      <th>first_manual_code</th>\n",
       "      <th>first_note</th>\n",
       "      <th>eadid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>field</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12335</th>\n",
       "      <td>“Thomas Sharp – an appreciation” by Lewis Keeble.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THS</td>\n",
       "      <td>THS 56.2</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>32934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>“Thomas Sharp – an appreciation” by Lewis Keeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THS</td>\n",
       "      <td>THS 56.2</td>\n",
       "      <td>scopecontent</td>\n",
       "      <td>32933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc  second_manual_code  \\\n",
       "12335  “Thomas Sharp – an appreciation” by Lewis Keeble.                 NaN   \n",
       "12336  “Thomas Sharp – an appreciation” by Lewis Keeb...                 NaN   \n",
       "\n",
       "       second_note baseline_prediction lcosc_prediction first_manual_code  \\\n",
       "12335          NaN                                                    NaN   \n",
       "12336          NaN                                                    NaN   \n",
       "\n",
       "      first_note eadid     rowid         field  description_id  \n",
       "12335        NaN   THS  THS 56.2     unittitle           32934  \n",
       "12336        NaN   THS  THS 56.2  scopecontent           32933  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf = df.drop(columns=[\"token_id\", \"index\", \"linguistic_prediction\", \"gender_bias_manual\", \"omission_manual\", \"stereotype_manual\"])\n",
    "subdf = subdf.rename(columns={\"type\":\"first_manual_code\", \"note\":\"first_note\"})\n",
    "subdf = subdf[[\n",
    "    \"doc\", \"baseline_prediction\", \"lcosc_prediction\", \"first_manual_code\", \"first_note\",\n",
    "      \"eadid\", \"rowid\", \"field\", \"description_id\"\n",
    "    ]]\n",
    "subdf.insert(1, \"second_manual_code\", np.nan)\n",
    "subdf.insert(2, \"second_note\", np.nan)\n",
    "subdf.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>second_manual_code</th>\n",
       "      <th>second_note</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>lcosc_prediction</th>\n",
       "      <th>first_manual_code</th>\n",
       "      <th>first_note</th>\n",
       "      <th>eadid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>field</th>\n",
       "      <th>description_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drafts and meeting notes relating to the creat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/01/01</td>\n",
       "      <td>scopecontent</td>\n",
       "      <td>11452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHE Supporters Review</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/02/04</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>11467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friend Newcastle Annual Reports</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/02/06</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>11471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Collection of documents on sex education in sc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/03/06/12</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>11554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Letters, newsletters and leaflets on the topic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/03/06/13</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>11555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc  second_manual_code  \\\n",
       "0  Drafts and meeting notes relating to the creat...                 NaN   \n",
       "1                              CHE Supporters Review                 NaN   \n",
       "2                    Friend Newcastle Annual Reports                 NaN   \n",
       "3  Collection of documents on sex education in sc...                 NaN   \n",
       "4  Letters, newsletters and leaflets on the topic...                 NaN   \n",
       "\n",
       "   second_note baseline_prediction lcosc_prediction first_manual_code  \\\n",
       "0          NaN                                                    NaN   \n",
       "1          NaN                                                    NaN   \n",
       "2          NaN                                                    NaN   \n",
       "3          NaN                                                    NaN   \n",
       "4          NaN                                                    NaN   \n",
       "\n",
       "  first_note eadid         rowid         field  description_id  \n",
       "0        NaN   CHE     CHE/01/01  scopecontent           11452  \n",
       "1        NaN   CHE     CHE/02/04     unittitle           11467  \n",
       "2        NaN   CHE     CHE/02/06     unittitle           11471  \n",
       "3        NaN   CHE  CHE/03/06/12     unittitle           11554  \n",
       "4        NaN   CHE  CHE/03/06/13     unittitle           11555  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf.to_csv(dir+\"manually_coded_and_classified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir1 = \"data/manually_coded_part2/group1/\"\n",
    "new_dir2 = \"data/manually_coded_part2/group2/\"\n",
    "Path(new_dir1).mkdir(parents=True, exist_ok=True)\n",
    "Path(new_dir2).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# eadids1 = [\"BP\", \"HL\", \"THS\"]\n",
    "# eadids2 = [\"BXB\", \"CHE\", \"OBR\", \"SH\", \"SW\", \"WCT\"]\n",
    "# subdf1 = subdf[subdf[\"eadid\"].isin(eadids1)]\n",
    "# subdf2 = subdf[subdf[\"eadid\"].isin(eadids2)]\n",
    "subdf3 = subdf[subdf[\"eadid\"] == \"CPT\"]\n",
    "\n",
    "# subdf1.to_csv(new_dir1+\"manually_coded_and_classified.csv\")\n",
    "# subdf2.to_csv(new_dir2+\"manually_coded_and_classified.csv\")\n",
    "subdf3.to_csv(new_dir2+\"manually_coded_and_classified_CPT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ii\"></a>\n",
    "### II. Analyze Agreement, part 1\n",
    "##### Compare manual codes to model classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize manually coded and classified columns and values, creating columns for `omission_baseline`, `stereotype_baseline`, `omission_lcosc`, and `stereotype_lcosc`, and noting the presence of a code with `'y'` and the absence of a code with `'n'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>index</th>\n",
       "      <th>doc</th>\n",
       "      <th>linguistic_prediction</th>\n",
       "      <th>gender_bias_manual</th>\n",
       "      <th>omission_manual</th>\n",
       "      <th>stereotype_manual</th>\n",
       "      <th>type</th>\n",
       "      <th>note</th>\n",
       "      <th>eadid</th>\n",
       "      <th>rowid</th>\n",
       "      <th>field</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>lcosc_prediction</th>\n",
       "      <th>omission_baseline</th>\n",
       "      <th>stereotype_baseline</th>\n",
       "      <th>omission_lcosc</th>\n",
       "      <th>stereotype_lcosc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11452</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>11452</td>\n",
       "      <td>Drafts and meeting notes relating to the creat...</td>\n",
       "      <td>['O']</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/01/01</td>\n",
       "      <td>scopecontent</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11467</td>\n",
       "      <td>[16, 17, 15]</td>\n",
       "      <td>11467</td>\n",
       "      <td>CHE Supporters Review</td>\n",
       "      <td>['O']</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHE</td>\n",
       "      <td>CHE/02/04</td>\n",
       "      <td>unittitle</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_id                                           token_id  index  \\\n",
       "0           11452  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  11452   \n",
       "1           11467                                       [16, 17, 15]  11467   \n",
       "\n",
       "                                                 doc linguistic_prediction  \\\n",
       "0  Drafts and meeting notes relating to the creat...                 ['O']   \n",
       "1                              CHE Supporters Review                 ['O']   \n",
       "\n",
       "  gender_bias_manual omission_manual stereotype_manual type note eadid  \\\n",
       "0                  n               n                 n   []  NaN   CHE   \n",
       "1                  n               n                 n   []  NaN   CHE   \n",
       "\n",
       "       rowid         field baseline_prediction lcosc_prediction  \\\n",
       "0  CHE/01/01  scopecontent                  []               []   \n",
       "1  CHE/02/04     unittitle                  []               []   \n",
       "\n",
       "  omission_baseline stereotype_baseline omission_lcosc stereotype_lcosc  \n",
       "0                 n                   n              n                n  \n",
       "1                 n                   n              n                n  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"baseline_prediction\", \"lcosc_prediction\"]\n",
    "for col in cols:\n",
    "    df_col = list(df[col])\n",
    "    omission_clfs = [\"y\" if \"Omission\" in pred else \"n\" for pred in df_col]\n",
    "    stereotype_clfs = [\"y\" if \"Stereotype\" in pred else \"n\" for pred in df_col]\n",
    "    if \"baseline\" in col:\n",
    "        suffix = \"_baseline\"\n",
    "    else:\n",
    "        suffix = \"_lcosc\"\n",
    "    df.insert(column=\"omission\"+suffix, value=omission_clfs, loc=(len(df.columns)))\n",
    "    df.insert(column=\"stereotype\"+suffix, value=stereotype_clfs, loc=(len(df.columns)))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = joblib.load(\"models/transform_labels/mlb_targets_os.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyhavens/miniconda3/envs/gender-bias-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:895: UserWarning: unknown class(es) [''] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_manual = mlb.transform(df[\"type\"])\n",
    "y_baseline = mlb.transform(df[\"baseline_prediction\"])\n",
    "y_lcosc = mlb.transform(df[\"lcosc_prediction\"])\n",
    "# print(y_baseline[190:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ii-i\"></a>\n",
    "##### i. Agreement: Manual vs. Baseline OSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[12134   156]\n",
      "  [   37    10]]\n",
      "\n",
      " [[12327     5]\n",
      "  [    5     0]]]\n"
     ]
    }
   ],
   "source": [
    "matrix = multilabel_confusion_matrix(y_manual, y_baseline, labels=[0,1])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>true_neg</th>\n",
       "      <th>false_neg</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omission</td>\n",
       "      <td>12134</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>156</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.093897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>12327</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  true_neg  false_neg  true_pos  false_pos  precision    recall  \\\n",
       "0    Omission     12134         37        10        156   0.060241  0.212766   \n",
       "1  Stereotype     12327          5         0          5   0.000000  0.000000   \n",
       "\n",
       "        f_1  \n",
       "0  0.093897  \n",
       "1  0.000000  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = matrix[:, 0, 0]  # True negatives\n",
    "fn = matrix[:, 1, 0]  # False negatives\n",
    "tp = matrix[:, 1, 1]  # True positives\n",
    "fp = matrix[:, 0, 1]  # False positives\n",
    "class_names = list(mlb.classes_)\n",
    "\n",
    "[precision, recall, f_1, suport] = precision_recall_fscore_support(\n",
    "    y_manual, y_baseline, beta=1.0, zero_division=0, labels=[0,1]\n",
    ")\n",
    "\n",
    "baseline_agmt_df = pd.DataFrame({\n",
    "    \"labels\":class_names, \"true_neg\":tn, \"false_neg\":fn, \"true_pos\":tp, \"false_pos\":fp,\n",
    "    \"precision\":precision, \"recall\":recall, \"f_1\":f_1\n",
    "})\n",
    "baseline_agmt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro scores:\n",
      "precision    0.030120\n",
      "recall       0.106383\n",
      "f_1          0.046948\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro scores:\")\n",
    "print(baseline_agmt_df[[\"precision\", \"recall\", \"f_1\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro scores:\n",
      "precision \t 0.05847953216374269\n",
      "recall \t\t 0.19230769230769232\n",
      "f_1 \t\t 0.08968609865470853\n"
     ]
    }
   ],
   "source": [
    "precision, recall, F1 = clf_utils.precisionRecallF1(sum(tp), sum(fp), sum(fn))\n",
    "print(\"Micro scores:\")\n",
    "print(\"precision \\t\", precision)\n",
    "print(\"recall \\t\\t\", recall)\n",
    "print(\"f_1 \\t\\t\", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ii-ii\"></a>\n",
    "##### ii. Manual vs. LCOSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[12012   278]\n",
      "  [   31    16]]\n",
      "\n",
      " [[12326     6]\n",
      "  [    5     0]]]\n"
     ]
    }
   ],
   "source": [
    "matrix = multilabel_confusion_matrix(y_manual, y_lcosc, labels=[0,1])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>true_neg</th>\n",
       "      <th>false_neg</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omission</td>\n",
       "      <td>12012</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>278</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.093842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>12326</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  true_neg  false_neg  true_pos  false_pos  precision    recall  \\\n",
       "0    Omission     12012         31        16        278   0.054422  0.340426   \n",
       "1  Stereotype     12326          5         0          6   0.000000  0.000000   \n",
       "\n",
       "        f_1  \n",
       "0  0.093842  \n",
       "1  0.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = matrix[:, 0, 0]  # True negatives\n",
    "fn = matrix[:, 1, 0]  # False negatives\n",
    "tp = matrix[:, 1, 1]  # True positives\n",
    "fp = matrix[:, 0, 1]  # False positives\n",
    "class_names = list(mlb.classes_)\n",
    "\n",
    "[precision, recall, f_1, suport] = precision_recall_fscore_support(\n",
    "    y_manual, y_lcosc, beta=1.0, zero_division=0, labels=[0,1]\n",
    ")\n",
    "\n",
    "lcosc_agmt_df = pd.DataFrame({\n",
    "    \"labels\":class_names, \"true_neg\":tn, \"false_neg\":fn, \"true_pos\":tp, \"false_pos\":fp,\n",
    "    \"precision\":precision, \"recall\":recall, \"f_1\":f_1\n",
    "})\n",
    "lcosc_agmt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro scores:\n",
      "precision    0.027211\n",
      "recall       0.170213\n",
      "f_1          0.046921\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro scores:\")\n",
    "print(lcosc_agmt_df[[\"precision\", \"recall\", \"f_1\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro scores:\n",
      "precision \t 0.05333333333333334\n",
      "recall \t\t 0.3076923076923077\n",
      "f_1 \t\t 0.09090909090909093\n"
     ]
    }
   ],
   "source": [
    "precision, recall, F1 = clf_utils.precisionRecallF1(sum(tp), sum(fp), sum(fn))\n",
    "print(\"Micro scores:\")\n",
    "print(\"precision \\t\", precision)\n",
    "print(\"recall \\t\\t\", recall)\n",
    "print(\"f_1 \\t\\t\", F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ii-iii\"></a>\n",
    "##### iii. Agreement: Baseline OSC vs. LCOSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[12005   166]\n",
      "  [   38   128]]\n",
      "\n",
      " [[12331     1]\n",
      "  [    0     5]]]\n"
     ]
    }
   ],
   "source": [
    "matrix = multilabel_confusion_matrix(y_baseline, y_lcosc, labels=[0,1])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>true_neg</th>\n",
       "      <th>false_neg</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omission</td>\n",
       "      <td>12005</td>\n",
       "      <td>38</td>\n",
       "      <td>128</td>\n",
       "      <td>166</td>\n",
       "      <td>0.435374</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.556522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stereotype</td>\n",
       "      <td>12331</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels  true_neg  false_neg  true_pos  false_pos  precision    recall  \\\n",
       "0    Omission     12005         38       128        166   0.435374  0.771084   \n",
       "1  Stereotype     12331          0         5          1   0.833333  1.000000   \n",
       "\n",
       "        f_1  \n",
       "0  0.556522  \n",
       "1  0.909091  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = matrix[:, 0, 0]  # True negatives\n",
    "fn = matrix[:, 1, 0]  # False negatives\n",
    "tp = matrix[:, 1, 1]  # True positives\n",
    "fp = matrix[:, 0, 1]  # False positives\n",
    "class_names = list(mlb.classes_)\n",
    "\n",
    "[precision, recall, f_1, suport] = precision_recall_fscore_support(\n",
    "    y_baseline, y_lcosc, beta=1.0, zero_division=0, labels=[0,1]\n",
    ")\n",
    "\n",
    "osc_agmt_df = pd.DataFrame({\n",
    "    \"labels\":class_names, \"true_neg\":tn, \"false_neg\":fn, \"true_pos\":tp, \"false_pos\":fp,\n",
    "    \"precision\":precision, \"recall\":recall, \"f_1\":f_1\n",
    "})\n",
    "osc_agmt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro scores:\n",
      "precision    0.634354\n",
      "recall       0.885542\n",
      "f_1          0.732806\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro scores:\")\n",
    "print(osc_agmt_df[[\"precision\", \"recall\", \"f_1\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro scores:\n",
      "precision \t 0.44333333333333336\n",
      "recall \t\t 0.7777777777777778\n",
      "f_1 \t\t 0.5647558386411891\n"
     ]
    }
   ],
   "source": [
    "precision, recall, F1 = clf_utils.precisionRecallF1(sum(tp), sum(fp), sum(fn))\n",
    "print(\"Micro scores:\")\n",
    "print(\"precision \\t\", precision)\n",
    "print(\"recall \\t\\t\", recall)\n",
    "print(\"f_1 \\t\\t\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender-bias-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
